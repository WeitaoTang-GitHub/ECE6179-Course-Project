{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> ECE4179 - Semi-Supervised Learning Project</h1>\n",
    "<h2>Data</h2>\n",
    "\n",
    "We will be using a dataset that can be obtained directly from the torchvision package. There are 10 classes and we will be training a CNN for the image classification task. We have training, validation and test sets that are labelled with the class, and a large unlabeled set.\n",
    "\n",
    "We will simulating a low training data scenario by only sampling a small percentage of the labelled data (10%) as training data. The remaining examples will be used as the validation set.\n",
    "\n",
    "To get the labelled data, change the dataset_dir to something suitable for your machine, and execute the following (you will then probably want to wrap the dataset objects in a PyTorch DataLoader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import STL10 as STL10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "####### CHANGE TO APPROPRIATE DIRECTORY TO STORE DATASET\n",
    "dataset_dir = r\"\\\\ad.monash.edu\\home\\User030\\rbea0007\\Documents\\ECE6179\\VS Code\\Course Project\"\n",
    "#For MonARCH\n",
    "# dataset_dir = \"/mnt/lustre/projects/ds19/SHARED\"\n",
    "\n",
    "#All images are 3x96x96\n",
    "image_size = 96\n",
    "#Example batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.is_available())  # Should return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create the appropriate transforms</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform random crops and mirroring for data augmentation\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomCrop(image_size, padding=4),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform_unlabelled = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#No random \n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.CenterCrop(image_size),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create training and validation split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Load train and validation sets\n",
    "trainval_set = STL10(dataset_dir, split='train', transform=transform_train, download=True)\n",
    "\n",
    "#Use 10% of data for training - simulating low data scenario\n",
    "num_train = int(len(trainval_set)*0.1)\n",
    "\n",
    "#Split data into train/val sets\n",
    "torch.manual_seed(0) #Set torch's random seed so that random split of data is reproducible\n",
    "train_set, val_set = random_split(trainval_set, [num_train, len(trainval_set)-num_train])\n",
    "\n",
    "#Load test set\n",
    "test_set = STL10(dataset_dir, split='test', transform=transform_test, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get the unlabelled data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "unlabelled_set = STL10(dataset_dir, split='unlabeled', transform=transform_unlabelled, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find later that you want to make changes to how the unlabelled data is loaded. This might require you sub-classing the STL10 class used above or to create your own dataloader similar to the Pytorch one.\n",
    "https://pytorch.org/docs/stable/_modules/torchvision/datasets/stl10.html#STL10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create the four dataloaders</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "unlabelled_loader = DataLoader(unlabelled_set, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "valid_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "Let's use a ResNet18 architecture for our CNN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model to compare results to\n",
    "# model = torchvision.models.resnet18()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum Contrast Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoCo(nn.Module):\n",
    "    def __init__(self, base_encoder, dim=128, K=8192, m=0.999, T=0.07):\n",
    "        super(MoCo, self).__init__()\n",
    "        self.encoder_q = base_encoder\n",
    "        self.encoder_k = base_encoder\n",
    "\n",
    "        # Replace the final layer to output the desired dimension\n",
    "        self.encoder_q.fc = nn.Linear(self.encoder_q.fc.in_features, dim)\n",
    "        self.encoder_k.fc = nn.Linear(self.encoder_k.fc.in_features, dim)\n",
    "        \n",
    "        for param in self.encoder_k.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "        self.K = K # queue size\n",
    "        self.m = m # momentum\n",
    "        self.T = T # temperature\n",
    "\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))  # Register queue as a buffer\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))  # Pointer for queue\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        q = self.encoder_q(x)\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "        return q\n",
    "    \n",
    "    @torch.no_grad()   \n",
    "    def update_key_encoder(self):\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def enqueue_and_dequeue(self, keys):\n",
    "        keys = nn.functional.normalize(keys, dim=1)\n",
    "        batch_size = keys.shape[0]\n",
    "        ptr = int(self.queue_ptr.item())\n",
    "\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.T\n",
    "        ptr = (ptr + batch_size) % self.K\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    def contrastive_loss(self, query):\n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        # Compute logits\n",
    "        logits = torch.mm(query, self.queue.clone().detach()) / self.T\n",
    "        labels = torch.arange(batch_size).cuda()\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\rbea0007/.cache\\torch\\hub\\pytorch_vision_main\n"
     ]
    }
   ],
   "source": [
    "# Initialise model using resnet18\n",
    "model_resnet = torch.hub.load('pytorch/vision', 'resnet18', weights=\"ResNet18_Weights.IMAGENET1K_V1\")\n",
    "base_encoder = model_resnet\n",
    "#base_encoder.fc = nn.Identity()\n",
    "model_moco = MoCo(base_encoder, dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/10], Loss: 9.7482\n",
      "Epoch [2/10], Loss: 10.0628\n",
      "Epoch [3/10], Loss: 10.1734\n",
      "Epoch [4/10], Loss: 9.4327\n",
      "Epoch [5/10], Loss: 10.4353\n",
      "Epoch [6/10], Loss: 9.6153\n",
      "Epoch [7/10], Loss: 9.5417\n",
      "Epoch [8/10], Loss: 10.2128\n",
      "Epoch [9/10], Loss: 9.7266\n",
      "Epoch [10/10], Loss: 9.8079\n"
     ]
    }
   ],
   "source": [
    "# Pretrain on unlabelled data\n",
    "def pretrain_model(model, dataloader, num_epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device)  # Move the model to the appropriate device\n",
    "\n",
    "    model.train()\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, _ in dataloader:\n",
    "            images = images.cuda()\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Generate augmented views\n",
    "            images_q = images  # Original images as query\n",
    "            #images_k = images(transform_unlabelled) # You can apply different augmentations\n",
    "            images_k = images\n",
    "            \n",
    "            # Forward pass\n",
    "            query = model(images_q)\n",
    "            query.requires_grad_()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.update_key_encoder()  # Update the key encoder\n",
    "                key = model.encoder_k(images_k)\n",
    "\n",
    "            # Contrastive loss\n",
    "            loss = model.contrastive_loss(query)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            # Update key encoder\n",
    "            model.enqueue_and_dequeue(key)\n",
    "            #model.update_key_encoder()\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Pretrain the model\n",
    "#model_moco.cuda()  # Move model to GPU\n",
    "pretrain_model(model_moco, unlabelled_loader, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader): # accuracy only\n",
    "    # Define the device inside the function\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move the model to the appropriate device\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "evaluate_model(model_moco, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.1295\n",
      "Epoch [2/10], Loss: 1.8836\n",
      "Epoch [3/10], Loss: 1.8685\n",
      "Epoch [4/10], Loss: 1.9443\n",
      "Epoch [5/10], Loss: 1.8252\n",
      "Epoch [6/10], Loss: 1.8322\n",
      "Epoch [7/10], Loss: 1.8002\n",
      "Epoch [8/10], Loss: 1.6823\n",
      "Epoch [9/10], Loss: 1.7423\n",
      "Epoch [10/10], Loss: 1.7654\n"
     ]
    }
   ],
   "source": [
    "# Fine tune the model\n",
    "num_classes = 10  # Adjust this based on your dataset\n",
    "model_moco.encoder_q.fc = nn.Linear(model_moco.encoder_q.fc.in_features, num_classes)\n",
    "\n",
    "def finetune_model(model, train_loader, val_loader, num_epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move the model to the appropriate device\n",
    "\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "finetune_model(model_moco, train_loader, valid_loader, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.99%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate finetuned model\n",
    "model_moco.eval()\n",
    "evaluate_model(model_moco, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
