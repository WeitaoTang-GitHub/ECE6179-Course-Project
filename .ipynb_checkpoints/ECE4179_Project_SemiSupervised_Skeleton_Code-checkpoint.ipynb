{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> ECE4179 - Semi-Supervised Learning Project</h1>\n",
    "<h2>Data</h2>\n",
    "\n",
    "We will be using a dataset that can be obtained directly from the torchvision package. There are 10 classes and we will be training a CNN for the image classification task. We have training, validation and test sets that are labelled with the class, and a large unlabeled set.\n",
    "\n",
    "We will simulating a low training data scenario by only sampling a small percentage of the labelled data (10%) as training data. The remaining examples will be used as the validation set.\n",
    "\n",
    "To get the labelled data, change the dataset_dir to something suitable for your machine, and execute the following (you will then probably want to wrap the dataset objects in a PyTorch DataLoader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import STL10 as STL10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Subset\n",
    "from copy import deepcopy\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "\n",
    "####### CHANGE TO APPROPRIATE DIRECTORY TO STORE DATASET\n",
    "dataset_dir = \"../../CNN-VAE/data\"\n",
    "#For MonARCH\n",
    "# dataset_dir = \"/mnt/lustre/projects/ds19/SHARED\"\n",
    "\n",
    "#All images are 3x96x96\n",
    "image_size = 96\n",
    "#Example batch size\n",
    "batch_size = 16\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "# Define the number of classes\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create the appropriate transforms</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform random crops and mirroring for data augmentation\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomCrop(image_size, padding=4),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform_unlabelled = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#No random \n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.CenterCrop(image_size),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create training and validation split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Load train and validation sets\n",
    "trainval_set = STL10(dataset_dir, split='train', transform=transform_train, download=True)\n",
    "\n",
    "#Use 10% of data for training - simulating low data scenario\n",
    "num_train = int(len(trainval_set)*0.1)\n",
    "\n",
    "#Split data into train/val sets\n",
    "torch.manual_seed(0) #Set torch's random seed so that random split of data is reproducible\n",
    "train_set, val_set = random_split(trainval_set, [num_train, len(trainval_set)-num_train])\n",
    "\n",
    "#Load test set\n",
    "test_set = STL10(dataset_dir, split='test', transform=transform_test, download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get the unlabelled data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "unlabelled_set = STL10(dataset_dir, split='unlabeled', transform=transform_unlabelled, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the length of unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unlabelled_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only get the 1/1000 for unlabled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the size of the subset (1/1000 of the full dataset)\n",
    "subset_size = len(unlabelled_set) // 1000  # This will be 100 samples\n",
    "\n",
    "# Randomly select indices for the subset\n",
    "random_indices = random.sample(range(len(unlabelled_set)), subset_size)\n",
    "\n",
    "# Create a subset of the unlabelled dataset\n",
    "unlabelled_subset = Subset(unlabelled_set, random_indices)\n",
    "\n",
    "# Now, create the DataLoader using the subset\n",
    "unlabelled_loader = DataLoader(unlabelled_subset, shuffle=True, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find later that you want to make changes to how the unlabelled data is loaded. This might require you sub-classing the STL10 class used above or to create your own dataloader similar to the Pytorch one.\n",
    "https://pytorch.org/docs/stable/_modules/torchvision/datasets/stl10.html#STL10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create the four dataloaders</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "valid_loader = DataLoader(val_set, batch_size=batch_size, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Accuracy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test function\n",
    "def test_model(model, test_loader):\n",
    "    # Define the device inside the function\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.to(device)  # Move the model to the appropriate device\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the appropriate device\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Marco F1 Score</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test function to calculate F1 score\n",
    "def test_model_with_f1(model, test_loader):\n",
    "    # Define the device inside the function\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.to(device)  # Move the model to the appropriate device\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Collect all predictions and labels for F1-score calculation\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate the Macro F1-score for each class\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    # Alternatively, you can get a detailed report for all classes\n",
    "    report = classification_report(all_labels, all_preds, target_names=[f\"Class {i}\" for i in range(10)])\n",
    "    \n",
    "    print(f\"Macro F1-score: {f1}\")\n",
    "    print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "Let's use a ResNet18 architecture for our CNN..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataset wrapper to convert labels to tensors\n",
    "class TensorLabelDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        # Convert label to tensor\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_pseudo_labeling_and_grid_search(\n",
    "    model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    unlabelled_loader,\n",
    "    num_classes,\n",
    "    num_epochs=10,\n",
    "    learning_rate=0.001,\n",
    "    log_filename='training_log.csv',\n",
    "    model_name='resnet',\n",
    "    batch_size=64\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Ensure 'logs' directory exists for saving the best model\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "\n",
    "    ### Phase 1: Initial Training on Labeled Data ###\n",
    "\n",
    "    print(\"Starting Phase 1: Initial Training on Labeled Data...\")\n",
    "    # Copy the model for initial training\n",
    "    initial_model = deepcopy(model).to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(initial_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    initial_model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = initial_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Initial Training Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    ### Phase 2: Generate Pseudo-Labels for Unlabeled Data ###\n",
    "\n",
    "    print(\"Starting Phase 2: Generating Pseudo-Labels for Unlabeled Data...\")\n",
    "    initial_model.eval()\n",
    "    pseudo_labels = []\n",
    "    all_unlabelled_inputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in unlabelled_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = initial_model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            pseudo_labels.extend(predicted.cpu())\n",
    "            all_unlabelled_inputs.extend(inputs.cpu())\n",
    "\n",
    "    # Create a new dataset with unlabeled data and pseudo-labels\n",
    "    from torch.utils.data import TensorDataset, ConcatDataset\n",
    "\n",
    "    pseudo_dataset = TensorDataset(torch.stack(all_unlabelled_inputs), torch.stack(pseudo_labels))\n",
    "\n",
    "    ### Phase 3: Combine Labeled and Pseudo-Labeled Data ###\n",
    "\n",
    "    print(\"Combining Labeled and Pseudo-Labeled Data...\")\n",
    "    # Wrap train_loader.dataset to convert labels to tensors\n",
    "    tensor_train_dataset = TensorLabelDataset(train_loader.dataset)\n",
    "\n",
    "    # Combine datasets\n",
    "    combined_dataset = ConcatDataset([tensor_train_dataset, pseudo_dataset])\n",
    "\n",
    "    # Create new DataLoader\n",
    "    combined_loader = torch.utils.data.DataLoader(\n",
    "        combined_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    ### Phase 4: Retrain Model on Combined Data ###\n",
    "\n",
    "    print(\"Starting Phase 3: Retraining Model on Combined Data...\")\n",
    "    # Copy the initial model\n",
    "    retrain_model = deepcopy(initial_model).to(device)\n",
    "\n",
    "    # Optionally, you can reset the optimizer\n",
    "    optimizer = Adam(retrain_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Retraining loop\n",
    "    retrain_model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in combined_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = retrain_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(combined_loader)\n",
    "        print(f\"Retraining Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    ### Phase 5: Transfer Learning with Grid Search ###\n",
    "\n",
    "    print(\"Starting Phase 4: Transfer Learning with Grid Search...\")\n",
    "    # Define different layer unfreezing configurations based on model type\n",
    "    if model_name == 'resnet':\n",
    "        unfreeze_configs = {\n",
    "            'fc': ['fc'],\n",
    "            'fc+layer4': ['layer4', 'fc'],\n",
    "            'fc+layer3+layer4': ['layer3', 'layer4', 'fc'],\n",
    "        }\n",
    "    elif model_name == 'efficientnet':\n",
    "        unfreeze_configs = {\n",
    "            'fc': ['classifier.1'],\n",
    "            'fc+features8': ['features.8', 'classifier.1'],\n",
    "            'fc+features7+features8': ['features.7', 'features.8', 'classifier.1'],\n",
    "        }\n",
    "    elif model_name == 'vit':\n",
    "        unfreeze_configs = {\n",
    "            'fc': ['heads.head'],\n",
    "            'fc+encoder11': ['encoder.layers.encoder_layer_11', 'heads.head'],\n",
    "            'fc+encoder10+encoder11': ['encoder.layers.encoder_layer_10', 'encoder.layers.encoder_layer_11', 'heads.head'],\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Model name not recognized.\")\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_config = ''\n",
    "    best_model_state = None\n",
    "\n",
    "    # Open log file for recording training progress\n",
    "    with open(os.path.join('logs', log_filename), mode='w', newline='') as log_file:\n",
    "        log_writer = csv.writer(log_file)\n",
    "        log_writer.writerow(['Configuration', 'Epoch', 'Training Loss', 'Validation Macro F1'])\n",
    "\n",
    "        for config_name, layers_to_unfreeze in unfreeze_configs.items():\n",
    "            print(f\"\\nStarting Transfer Learning Phase with configuration: {config_name}\")\n",
    "\n",
    "            # Create a new model by copying the retrained model\n",
    "            finetune_model = deepcopy(retrain_model)\n",
    "\n",
    "            # Modify the final layer based on the model's layer names\n",
    "            if model_name == 'resnet':\n",
    "                feature_dim = finetune_model.fc.in_features\n",
    "                finetune_model.fc = nn.Linear(feature_dim, num_classes)\n",
    "            elif model_name == 'efficientnet':\n",
    "                feature_dim = finetune_model.classifier[1].in_features\n",
    "                finetune_model.classifier[1] = nn.Linear(feature_dim, num_classes)\n",
    "            elif model_name == 'vit':\n",
    "                feature_dim = finetune_model.heads.head.in_features\n",
    "                finetune_model.heads.head = nn.Linear(feature_dim, num_classes)\n",
    "            else:\n",
    "                raise ValueError(\"Model name not recognized.\")\n",
    "\n",
    "            # Freeze all layers first\n",
    "            for param in finetune_model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            # Unfreeze specified layers\n",
    "            for name, param in finetune_model.named_parameters():\n",
    "                for layer_name in layers_to_unfreeze:\n",
    "                    if name.startswith(layer_name):\n",
    "                        param.requires_grad = True\n",
    "                        print(f\"Unfreezing layer: {name}\")\n",
    "\n",
    "            finetune_model = finetune_model.to(device)\n",
    "\n",
    "            # Define loss function and optimizer for fine-tuning\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = Adam(filter(lambda p: p.requires_grad, finetune_model.parameters()), lr=learning_rate)\n",
    "\n",
    "            # Fine-tuning training loop\n",
    "            for epoch in range(num_epochs):\n",
    "                finetune_model.train()\n",
    "                running_loss = 0.0\n",
    "                for inputs, labels in train_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = finetune_model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "                avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "                # Validation\n",
    "                finetune_model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in valid_loader:\n",
    "                        inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        outputs = finetune_model(inputs)\n",
    "                        _, predicted = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "                # Calculate Macro F1 score\n",
    "                f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "                # Log results\n",
    "                log_writer.writerow([config_name, epoch + 1, avg_loss, f1])\n",
    "                print(f\"Config: {config_name}, Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Validation Macro F1: {f1:.4f}\")\n",
    "\n",
    "            # Update best model if current config is better\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_config = config_name\n",
    "                best_model_state = deepcopy(finetune_model.state_dict())\n",
    "\n",
    "    print(f\"\\nBest Configuration: {best_config} with Macro F1 Score: {best_f1}\")\n",
    "    # Save the best model\n",
    "    torch.save(best_model_state, os.path.join('logs', f\"best_model_{model_name}.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: conv1.weight, Shape: torch.Size([64, 3, 7, 7])\n",
      "Name: bn1.weight, Shape: torch.Size([64])\n",
      "Name: bn1.bias, Shape: torch.Size([64])\n",
      "Name: layer1.0.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Name: layer1.0.bn1.weight, Shape: torch.Size([64])\n",
      "Name: layer1.0.bn1.bias, Shape: torch.Size([64])\n",
      "Name: layer1.0.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Name: layer1.0.bn2.weight, Shape: torch.Size([64])\n",
      "Name: layer1.0.bn2.bias, Shape: torch.Size([64])\n",
      "Name: layer1.1.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Name: layer1.1.bn1.weight, Shape: torch.Size([64])\n",
      "Name: layer1.1.bn1.bias, Shape: torch.Size([64])\n",
      "Name: layer1.1.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Name: layer1.1.bn2.weight, Shape: torch.Size([64])\n",
      "Name: layer1.1.bn2.bias, Shape: torch.Size([64])\n",
      "Name: layer2.0.conv1.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Name: layer2.0.bn1.weight, Shape: torch.Size([128])\n",
      "Name: layer2.0.bn1.bias, Shape: torch.Size([128])\n",
      "Name: layer2.0.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Name: layer2.0.bn2.weight, Shape: torch.Size([128])\n",
      "Name: layer2.0.bn2.bias, Shape: torch.Size([128])\n",
      "Name: layer2.0.downsample.0.weight, Shape: torch.Size([128, 64, 1, 1])\n",
      "Name: layer2.0.downsample.1.weight, Shape: torch.Size([128])\n",
      "Name: layer2.0.downsample.1.bias, Shape: torch.Size([128])\n",
      "Name: layer2.1.conv1.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Name: layer2.1.bn1.weight, Shape: torch.Size([128])\n",
      "Name: layer2.1.bn1.bias, Shape: torch.Size([128])\n",
      "Name: layer2.1.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Name: layer2.1.bn2.weight, Shape: torch.Size([128])\n",
      "Name: layer2.1.bn2.bias, Shape: torch.Size([128])\n",
      "Name: layer3.0.conv1.weight, Shape: torch.Size([256, 128, 3, 3])\n",
      "Name: layer3.0.bn1.weight, Shape: torch.Size([256])\n",
      "Name: layer3.0.bn1.bias, Shape: torch.Size([256])\n",
      "Name: layer3.0.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Name: layer3.0.bn2.weight, Shape: torch.Size([256])\n",
      "Name: layer3.0.bn2.bias, Shape: torch.Size([256])\n",
      "Name: layer3.0.downsample.0.weight, Shape: torch.Size([256, 128, 1, 1])\n",
      "Name: layer3.0.downsample.1.weight, Shape: torch.Size([256])\n",
      "Name: layer3.0.downsample.1.bias, Shape: torch.Size([256])\n",
      "Name: layer3.1.conv1.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Name: layer3.1.bn1.weight, Shape: torch.Size([256])\n",
      "Name: layer3.1.bn1.bias, Shape: torch.Size([256])\n",
      "Name: layer3.1.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Name: layer3.1.bn2.weight, Shape: torch.Size([256])\n",
      "Name: layer3.1.bn2.bias, Shape: torch.Size([256])\n",
      "Name: layer4.0.conv1.weight, Shape: torch.Size([512, 256, 3, 3])\n",
      "Name: layer4.0.bn1.weight, Shape: torch.Size([512])\n",
      "Name: layer4.0.bn1.bias, Shape: torch.Size([512])\n",
      "Name: layer4.0.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Name: layer4.0.bn2.weight, Shape: torch.Size([512])\n",
      "Name: layer4.0.bn2.bias, Shape: torch.Size([512])\n",
      "Name: layer4.0.downsample.0.weight, Shape: torch.Size([512, 256, 1, 1])\n",
      "Name: layer4.0.downsample.1.weight, Shape: torch.Size([512])\n",
      "Name: layer4.0.downsample.1.bias, Shape: torch.Size([512])\n",
      "Name: layer4.1.conv1.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Name: layer4.1.bn1.weight, Shape: torch.Size([512])\n",
      "Name: layer4.1.bn1.bias, Shape: torch.Size([512])\n",
      "Name: layer4.1.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Name: layer4.1.bn2.weight, Shape: torch.Size([512])\n",
      "Name: layer4.1.bn2.bias, Shape: torch.Size([512])\n",
      "Name: fc.weight, Shape: torch.Size([1000, 512])\n",
      "Name: fc.bias, Shape: torch.Size([1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\weita/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# We will keep this for later\n",
    "model0 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "\n",
    "\n",
    "for name, param in model0.named_parameters():\n",
    "    print(f\"Name: {name}, Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting Phase 1: Initial Training on Labeled Data...\n",
      "Initial Training Epoch [1/10], Loss: 3.4981\n",
      "Initial Training Epoch [2/10], Loss: 1.5099\n",
      "Initial Training Epoch [3/10], Loss: 0.9794\n",
      "Initial Training Epoch [4/10], Loss: 0.9971\n",
      "Initial Training Epoch [5/10], Loss: 0.9152\n",
      "Initial Training Epoch [6/10], Loss: 0.7804\n",
      "Initial Training Epoch [7/10], Loss: 0.6554\n",
      "Initial Training Epoch [8/10], Loss: 0.5819\n",
      "Initial Training Epoch [9/10], Loss: 0.6586\n",
      "Initial Training Epoch [10/10], Loss: 0.7637\n",
      "Starting Phase 2: Generating Pseudo-Labels for Unlabeled Data...\n",
      "Combining Labeled and Pseudo-Labeled Data...\n",
      "Starting Phase 3: Retraining Model on Combined Data...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 317, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 174, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 174, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 211, in collate_tensor_fn\n    numel = sum(x.numel() for x in batch)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 211, in <genexpr>\n    numel = sum(x.numel() for x in batch)\n                ^^^^^^^\nAttributeError: 'int' object has no attribute 'numel'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model_resnet18 \u001b[38;5;241m=\u001b[39m deepcopy(model0)  \u001b[38;5;66;03m# assuming model0 is a pretrained resnet18\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model_resnet18 \u001b[38;5;241m=\u001b[39m model_resnet18\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 4\u001b[0m train_model_with_pseudo_labeling_and_grid_search(\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_resnet18,\n\u001b[0;32m      6\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m      7\u001b[0m     valid_loader\u001b[38;5;241m=\u001b[39mvalid_loader,\n\u001b[0;32m      8\u001b[0m     unlabelled_loader\u001b[38;5;241m=\u001b[39munlabelled_loader,\n\u001b[0;32m      9\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[0;32m     10\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[0;32m     11\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m     12\u001b[0m     log_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet18_training_log.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[0;32m     15\u001b[0m )\n",
      "Cell \u001b[1;32mIn[10], line 92\u001b[0m, in \u001b[0;36mtrain_model_with_pseudo_labeling_and_grid_search\u001b[1;34m(model, train_loader, valid_loader, unlabelled_loader, num_classes, num_epochs, learning_rate, log_filename, model_name, batch_size)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     91\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m combined_loader:\n\u001b[0;32m     93\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     94\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1370\u001b[0m     data\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 317, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 174, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 174, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 211, in collate_tensor_fn\n    numel = sum(x.numel() for x in batch)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\weita\\anaconda3\\envs\\ECE4179_CV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 211, in <genexpr>\n    numel = sum(x.numel() for x in batch)\n                ^^^^^^^\nAttributeError: 'int' object has no attribute 'numel'\n"
     ]
    }
   ],
   "source": [
    "# Example usage with ResNet18\n",
    "model_resnet18 = deepcopy(model0)  # assuming model0 is a pretrained resnet18\n",
    "model_resnet18 = model_resnet18.to(device)\n",
    "train_model_with_pseudo_labeling_and_grid_search(\n",
    "    model=model_resnet18,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    unlabelled_loader=unlabelled_loader,\n",
    "    num_classes=num_classes,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    log_filename='resnet18_training_log.csv',\n",
    "    model_name='resnet',\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ResNet18 model\n",
    "best_model_resnet = models.resnet18(pretrained=False)\n",
    "best_model_resnet.fc = nn.Linear(best_model_resnet.fc.in_features, num_classes)\n",
    "best_model_resnet = best_model_resnet.to(device)\n",
    "\n",
    "# Load the best model weights\n",
    "best_model_resnet.load_state_dict(torch.load(f'logs/best_model_resnet.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "best_model_resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the test functions\n",
    "test_model(best_model_resnet, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_with_f1(best_model_resnet, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained EfficientNet-B0 model from torchvision hub\n",
    "model1 = torch.hub.load('pytorch/vision', 'efficientnet_b0', weights=\"EfficientNet_B0_Weights.IMAGENET1K_V1\")\n",
    "\n",
    "for name, param in model1.named_parameters():\n",
    "    print(f\"Name: {name}, Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with EfficientNetB0\n",
    "model_efficientnetb0 = deepcopy(model1)  # assuming model1 is a pretrained efficientnetb0\n",
    "model_efficientnetb0 = model_efficientnetb0.to(device)\n",
    "# Call the training function\n",
    "train_model_with_pseudo_labeling_and_grid_search(\n",
    "    model=model_efficientnetb0,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    unlabelled_loader=unlabelled_loader,\n",
    "    num_classes=num_classes,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    log_filename='efficientnetb0_training_log.csv',\n",
    "    model_name='efficientnet',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EfficientNetB0 model\n",
    "best_model_efficientnet = models.efficientnet_b0(pretrained=False)\n",
    "best_model_efficientnet.classifier[1] = nn.Linear(best_model_efficientnet.classifier[1].in_features, num_classes)\n",
    "best_model_efficientnet = best_model_efficientnet.to(device)\n",
    "\n",
    "# Load the best model weights\n",
    "best_config = 'fc+features8'  # Replace with your best configuration name\n",
    "best_model_efficientnet.load_state_dict(torch.load(f'logs/best_model_efficientnet.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "best_model_efficientnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the test function\n",
    "test_model(best_model_efficientnet, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to calculate and print F1-scores\n",
    "test_model_with_f1(best_model_efficientnet, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Transformer (ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image size to 224x224 to match the input size of ViT\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_unlabelled = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and validation sets without redownloading data\n",
    "trainval_set = STL10(dataset_dir, split='train', transform=transform_train, download=False)\n",
    "\n",
    "# Use 10% of the data for training (simulating a low data scenario)\n",
    "num_train = int(len(trainval_set) * 0.1)\n",
    "\n",
    "# Split data into train/validation sets with a fixed random seed\n",
    "torch.manual_seed(0)  # Ensure reproducibility\n",
    "train_set, val_set = random_split(trainval_set, [num_train, len(trainval_set) - num_train])\n",
    "\n",
    "# Load test set without redownloading data\n",
    "test_set = STL10(dataset_dir, split='test', transform=transform_test, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_set = STL10(dataset_dir, split='unlabeled', transform=transform_unlabelled, download=False)\n",
    "\n",
    "# Determine the size of the subset (1/1000 of the full dataset)\n",
    "subset_size = len(unlabelled_set) // 1000  # This will be 100 samples\n",
    "\n",
    "# Randomly select indices for the subset\n",
    "random_indices = random.sample(range(len(unlabelled_set)), subset_size)\n",
    "\n",
    "# Create a subset of the unlabelled dataset\n",
    "unlabelled_subset = Subset(unlabelled_set, random_indices)\n",
    "\n",
    "# Now, create the DataLoader using the subset\n",
    "unlabelled_loader = DataLoader(unlabelled_subset, shuffle=True, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for train, validation, and test sets\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "valid_loader = DataLoader(val_set, batch_size=batch_size, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained Vision Transformer (ViT) model from torchvision models\n",
    "model2 = models.vit_b_16(pretrained=True)\n",
    "\n",
    "# Print the model structure to verify the changes\n",
    "for name, param in model2.named_parameters():\n",
    "    print(f\"Name: {name}, Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with Vision Transformer (ViT)\n",
    "model_vit = deepcopy(model2)  # assuming model2 is a pretrained Vision Transformer (ViT)\n",
    "model_vit = model_vit.to(device)\n",
    "\n",
    "# Call the training function\n",
    "train_model_with_pseudo_labeling_and_grid_search(\n",
    "    model=model_vit,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    unlabelled_loader=unlabelled_loader,\n",
    "    num_classes=num_classes,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    log_filename='vit_training_log.csv',\n",
    "    model_name='vit',\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ViT model\n",
    "best_model_vit = models.vit_b_16(pretrained=False)\n",
    "best_model_vit.heads.head = nn.Linear(best_model_vit.heads.head.in_features, num_classes)\n",
    "best_model_vit = best_model_vit.to(device)\n",
    "\n",
    "# Load the best model weights\n",
    "best_config = 'fc+encoder11'  # Replace with your best configuration name\n",
    "best_model_vit.load_state_dict(torch.load(f'logs/best_model_vit.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "best_model_vit.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the test function\n",
    "test_model(best_model_vit, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to calculate and print F1-scores\n",
    "test_model_with_f1(best_model_vit, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
